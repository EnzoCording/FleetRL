{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2023 Enzo Alexander Cording - https://github.com/EnzoCording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:28.400794Z",
     "start_time": "2023-08-15T23:30:28.322570Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Literal\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from FleetRL.fleet_env import FleetEnv\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecNormalize, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback, ProgressBarCallback, BaseCallback\n",
    "from stable_baselines3.common.logger import HParam\n",
    "\n",
    "from pink import PinkActionNoise\n",
    "from stable_baselines3.common.noise import OrnsteinUhlenbeckActionNoise, NormalActionNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:28.401386Z",
     "start_time": "2023-08-15T23:30:28.371666Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define fundamental parameters\n",
    "run_name = \"LMD_2022_arbitrage_PPO\"\n",
    "n_train_steps = 48  # number of hours in a training episode\n",
    "n_eval_steps = 8600  # number of hours in one evaluation episode\n",
    "n_eval_episodes = 1  # number of episodes for evaluation\n",
    "n_evs = 2  # number of evs\n",
    "n_envs = 2  # number of envs parallel - has to be one if train_freq = (1, episode) (or default)\n",
    "time_steps_per_hour = 4  # temporal resolution\n",
    "use_case: str = \"lmd\"  # for file name\n",
    "scenario: Literal[\"arb\", \"tariff\"] = \"tariff\"  # arbitrage or tariff\n",
    "gen_new_schedule = True  # generate a new schedule - refer to schedule generator and its config to change settings\n",
    "gen_new_test_schedule = True  # generate a new schedule for agent testing\n",
    "\n",
    "# training parameters\n",
    "norm_obs_in_env = False  # normalize observations in FleetRL (max, min normalization)\n",
    "vec_norm_obs = True  # normalize observations in SB3 (rolling normalization)\n",
    "vec_norm_rew = True  # normalize rewards in SB3 (rolling normalization)\n",
    "total_steps = int(1e6)  # total training time steps\n",
    "saving_interval = 50000  # interval for saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:28.401744Z",
     "start_time": "2023-08-15T23:30:28.372857Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# environment arguments - adjust settings if necessary\n",
    "# additional settings can be changed in the config files\n",
    "env_kwargs = {\"schedule_name\": str(n_evs) + \"_\" + str(use_case) + \".csv\",\n",
    "              \"building_name\": \"load_\" + str(use_case) + \".csv\",\n",
    "              \"use_case\": use_case,\n",
    "              \"include_building\": True,\n",
    "              \"include_pv\": True,\n",
    "              \"time_picker\": \"random\",\n",
    "              \"deg_emp\": False,\n",
    "              \"include_price\": True,\n",
    "              \"ignore_price_reward\": False,\n",
    "              \"ignore_invalid_penalty\": False,\n",
    "              \"ignore_overcharging_penalty\": False,\n",
    "              \"ignore_overloading_penalty\": False,\n",
    "              \"episode_length\": n_train_steps,\n",
    "              \"normalize_in_env\": norm_obs_in_env,\n",
    "              \"verbose\": 0,\n",
    "              \"aux\": True,\n",
    "              \"log_data\": False,\n",
    "              \"calculate_degradation\": True,\n",
    "              \"target_soc\": 0.85,\n",
    "              \"gen_schedule\": gen_new_schedule,\n",
    "              \"gen_start_date\": \"2022-01-01 00:00\",\n",
    "              \"gen_end_date\": \"2022-12-31 23:59:59\",\n",
    "              \"gen_name\": \"my_sched.csv\",\n",
    "              \"gen_n_evs\": 1,\n",
    "              \"seed\": 42\n",
    "              }\n",
    "\n",
    "if scenario == \"tariff\":\n",
    "    env_kwargs[\"spot_markup\"] = 10\n",
    "    env_kwargs[\"spot_mul\"] = 1.5\n",
    "    env_kwargs[\"feed_in_ded\"] = 0.25\n",
    "    env_kwargs[\"price_name\"] = \"spot_2021_new.csv\"\n",
    "    env_kwargs[\"tariff_name\"] = \"fixed_feed_in.csv\"\n",
    "elif scenario == \"arb\":\n",
    "    env_kwargs[\"spot_markup\"] = 0\n",
    "    env_kwargs[\"spot_mul\"] = 1\n",
    "    env_kwargs[\"feed_in_ded\"] = 0\n",
    "    env_kwargs[\"price_name\"] = \"spot_2021_new.csv\"\n",
    "    env_kwargs[\"tariff_name\"] = \"spot_2021_new_tariff.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:38.039697Z",
     "start_time": "2023-08-15T23:30:28.373555Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vec_env = make_vec_env(FleetEnv,\n",
    "                             n_envs=n_envs,\n",
    "                             vec_env_cls=SubprocVecEnv,\n",
    "                             env_kwargs=env_kwargs)\n",
    "\n",
    "train_norm_vec_env = VecNormalize(venv=train_vec_env,\n",
    "                                  norm_obs=vec_norm_obs,\n",
    "                                  norm_reward=vec_norm_rew,\n",
    "                                  training=True,\n",
    "                                  clip_reward=10.0)\n",
    "\n",
    "env_kwargs[\"time_picker\"] = \"eval\"\n",
    "env_kwargs[\"gen_schedule\"] = False\n",
    "env_kwargs[\"schedule_name\"] = env_kwargs[\"gen_name\"]\n",
    "\n",
    "eval_vec_env = make_vec_env(FleetEnv,\n",
    "                             n_envs=n_envs,\n",
    "                             vec_env_cls=SubprocVecEnv,\n",
    "                             env_kwargs=env_kwargs)\n",
    "\n",
    "eval_norm_vec_env = VecNormalize(venv=eval_vec_env,\n",
    "                                  norm_obs=vec_norm_obs,\n",
    "                                  norm_reward=vec_norm_rew,\n",
    "                                  training=True,\n",
    "                                  clip_reward=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:47.029500Z",
     "start_time": "2023-08-15T23:30:38.044992Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating schedules... This may take a while.\n",
      "Schedule generation complete. Saved in Inputs path. File name: my_sched_test.csv\n"
     ]
    }
   ],
   "source": [
    "if gen_new_test_schedule:\n",
    "    # generate an evaluation schedule\n",
    "    test_sched_name = env_kwargs[\"gen_name\"]\n",
    "    if not test_sched_name.endswith(\".csv\"):\n",
    "        test_sched_name = test_sched_name + \"_test\" + \".csv\"\n",
    "    else:\n",
    "        test_sched_name = test_sched_name.strip(\".csv\")\n",
    "        test_sched_name = test_sched_name + \"_test\" + \".csv\"\n",
    "\n",
    "    env_kwargs[\"gen_schedule\"] = True\n",
    "    env_kwargs[\"gen_name\"] = test_sched_name\n",
    "\n",
    "    test_vec_env = make_vec_env(FleetEnv,\n",
    "                                n_envs=1,\n",
    "                                vec_env_cls=SubprocVecEnv,\n",
    "                                env_kwargs=env_kwargs)\n",
    "\n",
    "    env_kwargs[\"gen_schedule\"] = False\n",
    "    env_kwargs[\"schedule_name\"] = test_sched_name\n",
    "\n",
    "test_vec_env = make_vec_env(FleetEnv,\n",
    "                            n_envs=n_envs,\n",
    "                            vec_env_cls=SubprocVecEnv,\n",
    "                            env_kwargs=env_kwargs)\n",
    "\n",
    "test_norm_vec_env = VecNormalize(venv=test_vec_env,\n",
    "                                 norm_obs=vec_norm_obs,\n",
    "                                 norm_reward=vec_norm_rew,\n",
    "                                 training=True,\n",
    "                                 clip_reward=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:47.029855Z",
     "start_time": "2023-08-15T23:30:47.011411Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(eval_env=eval_norm_vec_env,\n",
    "                             warn=True,\n",
    "                             verbose=1,\n",
    "                             deterministic=True,\n",
    "                             eval_freq=max(10000 // n_envs, 1),\n",
    "                             n_eval_episodes=5,\n",
    "                             render=False,\n",
    "                             )\n",
    "\n",
    "class HyperParamCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Saves hyperparameters and metrics at start of training, logging to tensorboard\n",
    "    \"\"\"\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        hparam_dict = {\n",
    "            \"algorithm\": self.model.__class__.__name__,\n",
    "            \"learning rate\": self.model.learning_rate,\n",
    "            \"gamma\": self.model.gamma,\n",
    "        }\n",
    "\n",
    "        metric_dict = {\n",
    "            \"rollout/ep_len_mean\": 0,\n",
    "            \"train/value_loss\": 0.0,\n",
    "        }\n",
    "\n",
    "        self.logger.record(\n",
    "            \"hparams\",\n",
    "            HParam(hparam_dict, metric_dict),\n",
    "            exclude=(\"stdout\", \"log\", \"json\", \"csv\")\n",
    "        )\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        return True\n",
    "\n",
    "progress_bar = ProgressBarCallback()\n",
    "\n",
    "## wandb callback possible, check documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:47.030057Z",
     "start_time": "2023-08-15T23:30:47.011914Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyperparameter_callback = HyperParamCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:47.030383Z",
     "start_time": "2023-08-15T23:30:47.012356Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_actions = train_norm_vec_env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "noise_scale = 0.1\n",
    "seq_len = n_train_steps * time_steps_per_hour\n",
    "action_noise = PinkActionNoise(noise_scale, seq_len, n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:47.031022Z",
     "start_time": "2023-08-15T23:30:47.012790Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO(policy=\"MlpPolicy\",\n",
    "            verbose=1,\n",
    "            env=train_norm_vec_env,\n",
    "            tensorboard_log=\"./tb_log\",\n",
    "            gamma=0.993,\n",
    "            learning_rate=0.0005,\n",
    "            batch_size=128,\n",
    "            n_epochs=8,\n",
    "            gae_lambda=0.9,\n",
    "            clip_range=0.2,\n",
    "            clip_range_vf=None,\n",
    "            normalize_advantage=True,\n",
    "            ent_coef=0.0008,\n",
    "            vf_coef=0.5,\n",
    "            max_grad_norm=0.5,\n",
    "            n_steps=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:49.077647Z",
     "start_time": "2023-08-15T23:30:47.024046Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ./tb_log --bind_all --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T23:30:49.078123Z",
     "start_time": "2023-08-15T23:30:49.052213Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment = run_name\n",
    "time_now = int(time.time())\n",
    "trained_agents_dir = f\"./RL_agents/trained_agents/vec_PPO_{time_now}_{run_name}\"\n",
    "logs_dir = f\"./RL_agents/trained_agents/logs/vec_PPO_{time_now}_{run_name}\"\n",
    "\n",
    "if not os.path.exists(trained_agents_dir):\n",
    "    os.makedirs(trained_agents_dir)\n",
    "\n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0, int(total_steps / saving_interval)):\n",
    "    model.learn(total_timesteps=saving_interval,\n",
    "                reset_num_timesteps=False,\n",
    "                tb_log_name=f\"PPO_{time_now}_{comment}\",\n",
    "                callback=[eval_callback, hyperparameter_callback, progress_bar])\n",
    "\n",
    "    model.save(f\"{trained_agents_dir}/{saving_interval * i}\")\n",
    "\n",
    "    # Don't forget to save the VecNormalize statistics when saving the agent\n",
    "    log_dir = \"./RL_agents/trained_agents/tmp/vec_PPO/\"\n",
    "    model.save(log_dir + f\"PPO-fleet_{comment}_{time_now}\")\n",
    "    stats_path = os.path.join(log_dir, f\"vec_normalize-{comment}_{time_now}.pkl\")\n",
    "    train_norm_vec_env.save(stats_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
