{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66582a5d-8643-468f-917b-b61a0fa58c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T12:27:38.194134Z",
     "iopub.status.busy": "2023-07-27T12:27:38.193713Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import TD3, PPO\n",
    "from stable_baselines3.common.vec_env import VecNormalize, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from FleetRL.fleet_env.fleet_environment import FleetEnv\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#if True:\n",
    "    # define parameters here for easier change\n",
    "    n_steps = 8600\n",
    "    n_episodes = 1\n",
    "    n_evs = 1\n",
    "    n_envs = 1\n",
    "\n",
    "    # make env for the agent\n",
    "    eval_vec_env = make_vec_env(FleetEnv,\n",
    "                                n_envs=n_envs,\n",
    "                                vec_env_cls=SubprocVecEnv,\n",
    "                                seed=0,\n",
    "                                env_kwargs={\n",
    "                                    \"schedule_name\": \"lmd_sched_single_eval.csv\",\n",
    "                                    \"building_name\": \"load_lmd.csv\",\n",
    "                                    \"price_name\": \"spot_2021_new.csv\",\n",
    "                                    \"tariff_name\": \"spot_2021_new_tariff.csv\",\n",
    "                                    \"use_case\": \"lmd\",\n",
    "                                    \"include_building\": True,\n",
    "                                    \"include_pv\": True,\n",
    "                                    \"time_picker\": \"static\",\n",
    "                                    \"deg_emp\": False,\n",
    "                                    \"include_price\": True,\n",
    "                                    \"ignore_price_reward\": False,\n",
    "                                    \"ignore_invalid_penalty\": False,\n",
    "                                    \"ignore_overcharging_penalty\": False,\n",
    "                                    \"ignore_overloading_penalty\": False,\n",
    "                                    \"episode_length\": n_steps,\n",
    "                                    \"normalize_in_env\": False,\n",
    "                                    \"verbose\": 0,\n",
    "                                    \"aux\": True,\n",
    "                                    \"log_data\": True,\n",
    "                                    \"calculate_degradation\": True,\n",
    "                                    \"spot_markup\": 0,\n",
    "                                    \"spot_mul\": 1,\n",
    "                                    \"feed_in_ded\": 0\n",
    "                                })\n",
    "    # %%\n",
    "    eval_norm_vec_env = VecNormalize(venv=eval_vec_env,\n",
    "                                     norm_obs=True,\n",
    "                                     norm_reward=True,\n",
    "                                     training=True,\n",
    "                                     clip_reward=10.0)\n",
    "\n",
    "    dumb_vec_env = make_vec_env(FleetEnv,\n",
    "                                n_envs=n_envs,\n",
    "                                vec_env_cls=SubprocVecEnv,\n",
    "                                seed=0,\n",
    "                                env_kwargs={\n",
    "                                    \"schedule_name\": \"lmd_sched_single_eval.csv\",\n",
    "                                    \"building_name\": \"load_lmd.csv\",\n",
    "                                    \"price_name\": \"spot_2021_new.csv\",\n",
    "                                    \"tariff_name\": \"spot_2021_new_tariff.csv\",\n",
    "                                    \"use_case\": \"lmd\",\n",
    "                                    \"include_building\": True,\n",
    "                                    \"include_pv\": True,\n",
    "                                    \"time_picker\": \"static\",\n",
    "                                    \"deg_emp\": False,\n",
    "                                    \"include_price\": True,\n",
    "                                    \"ignore_price_reward\": False,\n",
    "                                    \"ignore_invalid_penalty\": False,\n",
    "                                    \"ignore_overcharging_penalty\": False,\n",
    "                                    \"ignore_overloading_penalty\": False,\n",
    "                                    \"episode_length\": n_steps,\n",
    "                                    \"normalize_in_env\": False,\n",
    "                                    \"verbose\": 0,\n",
    "                                    \"aux\": True,\n",
    "                                    \"log_data\": True,\n",
    "                                    \"calculate_degradation\": True,\n",
    "                                    \"spot_markup\": 0,\n",
    "                                    \"spot_mul\": 1,\n",
    "                                    \"feed_in_ded\": 0\n",
    "                                })\n",
    "    # %%\n",
    "    dumb_norm_vec_env = VecNormalize(venv=dumb_vec_env,\n",
    "                                     norm_obs=True,\n",
    "                                     norm_reward=True,\n",
    "                                     training=True,\n",
    "                                     clip_reward=10.0)\n",
    "\n",
    "    # %%\n",
    "    eval_norm_vec_env.load(load_path=\"./tmp/vec_PPO/vec_normalize-LMD_2021_arbitrage_PPO_mul3.pkl\", venv=eval_norm_vec_env)\n",
    "    model = PPO.load(\"./tmp/vec_PPO/PPO-fleet_LMD_2021_arbitrage_PPO_mul3.zip\", env = eval_norm_vec_env,\n",
    "                    custom_objects={\"observation_space\": eval_norm_vec_env.observation_space,\n",
    "                                   \"action_space\": eval_norm_vec_env.action_space})\n",
    "\n",
    "    #len = len(model.observation_space.low)\n",
    "    #model.observation_space.low = np.full(len, -np.inf)\n",
    "    #model.observation_space.high = np.full(len, np.inf)\n",
    "    #model.env = eval_norm_vec_env\n",
    "\n",
    "    # %%\n",
    "    mean_reward, _ = evaluate_policy(model, eval_norm_vec_env, n_eval_episodes=n_episodes, deterministic=True)\n",
    "    print(mean_reward)\n",
    "\n",
    "    # %%\n",
    "    log_RL = model.env.env_method(\"get_log\")[0]\n",
    "    rl_start_time = model.env.env_method(\"get_start_time\")[0]\n",
    "    dumb_norm_vec_env.env_method(\"set_start_time\", rl_start_time)\n",
    "    # %%\n",
    "    print(\"################################################################\")\n",
    "\n",
    "    episode_length = n_steps\n",
    "    timesteps_per_hour = 4\n",
    "    n_episodes = n_episodes\n",
    "    dumb_norm_vec_env.reset()\n",
    "\n",
    "    for i in range(episode_length * timesteps_per_hour * n_episodes):\n",
    "        if dumb_norm_vec_env.env_method(\"is_done\")[0]:\n",
    "            dumb_norm_vec_env.reset()\n",
    "        dumb_norm_vec_env.step([np.ones(n_evs)])\n",
    "\n",
    "    dumb_log = dumb_norm_vec_env.env_method(\"get_log\")[0]\n",
    "\n",
    "    log_RL.reset_index(drop=True, inplace=True)\n",
    "    log_RL = log_RL.iloc[0:-2]\n",
    "    dumb_log.reset_index(drop=True, inplace=True)\n",
    "    dumb_log = dumb_log.iloc[0:-2]\n",
    "\n",
    "    rl_cashflow = log_RL[\"Cashflow\"].sum()\n",
    "    rl_reward = log_RL[\"Reward\"].sum()\n",
    "    rl_deg = log_RL[\"Degradation\"].sum()\n",
    "    rl_overloading = log_RL[\"Grid overloading\"].sum()\n",
    "    rl_soc_violation = log_RL[\"SOC violation\"].sum()\n",
    "    rl_n_violations = log_RL[log_RL[\"SOC violation\"] > 0][\"SOC violation\"].size\n",
    "    rl_soh = log_RL[\"SOH\"].iloc[-1]\n",
    "\n",
    "    dumb_cashflow = dumb_log[\"Cashflow\"].sum()\n",
    "    dumb_reward = dumb_log[\"Reward\"].sum()\n",
    "    dumb_deg = dumb_log[\"Degradation\"].sum()\n",
    "    dumb_overloading = dumb_log[\"Grid overloading\"].sum()\n",
    "    dumb_soc_violation = dumb_log[\"SOC violation\"].sum()\n",
    "    dumb_n_violations = dumb_log[dumb_log[\"SOC violation\"] > 0][\"SOC violation\"].size\n",
    "    dumb_soh = dumb_log[\"SOH\"].iloc[-1]\n",
    "\n",
    "    print(f\"RL reward: {rl_reward}\")\n",
    "    print(f\"DC reward: {dumb_reward}\")\n",
    "    print(f\"RL cashflow: {rl_cashflow}\")\n",
    "    print(f\"DC cashflow: {dumb_cashflow}\")\n",
    "\n",
    "    total_results = pd.DataFrame()\n",
    "    total_results[\"Category\"] = [\"Reward\", \"Cashflow\", \"Average degradation per EV\", \"Overloading\", \"SOC violation\", \"# Violations\", \"SOH\"]\n",
    "\n",
    "    total_results[\"RL-based charging\"] = [rl_reward,\n",
    "                                          rl_cashflow,\n",
    "                                          np.round(np.mean(rl_deg), 5),\n",
    "                                          rl_overloading,\n",
    "                                          rl_soc_violation,\n",
    "                                          rl_n_violations,\n",
    "                                          np.round(np.mean(rl_soh), 5)]\n",
    "\n",
    "    total_results[\"Dumb charging\"] = [dumb_reward,\n",
    "                                      dumb_cashflow,\n",
    "                                      np.round(np.mean(dumb_deg), 5),\n",
    "                                      dumb_overloading,\n",
    "                                      dumb_soc_violation,\n",
    "                                      dumb_n_violations,\n",
    "                                      np.round(np.mean(dumb_soh), 5)]\n",
    "\n",
    "    print(total_results)\n",
    "\n",
    "\n",
    "    # real charging power sent\n",
    "    real_power_rl = []\n",
    "    for i in range(log_RL.__len__()):\n",
    "        log_RL.loc[i, \"hour_id\"] = (log_RL.loc[i, \"Time\"].hour + log_RL.loc[i, \"Time\"].minute / 60)\n",
    "        # real_power_rl.append({\"real_power\": (log_RL.loc[i, \"Action\"]\n",
    "        #                                      * log_RL.loc[i, \"Observation\"][2 * n_evs + 19:2 * n_evs + 19 + n_evs]\n",
    "        #                                      * log_RL.loc[i, \"Observation\"][-4])})\n",
    "\n",
    "    #log_RL = pd.concat((log_RL, pd.DataFrame(real_power_rl)), axis=1)\n",
    "\n",
    "    real_power_dumb = []\n",
    "    for i in range(dumb_log.__len__()):\n",
    "        dumb_log.loc[i, \"hour_id\"] = (dumb_log.loc[i, \"Time\"].hour + dumb_log.loc[i, \"Time\"].minute / 60)\n",
    "        # real_power_dumb.append({\"real_power\": (dumb_log.loc[i, \"Action\"]\n",
    "        #                                        * dumb_log.loc[i, \"Observation\"][2 * n_evs + 19:2 * n_evs + 19 + n_evs]\n",
    "        #                                        * dumb_log.loc[i, \"Observation\"][4 * n_evs + 19:4 * n_evs + 19 + n_evs]\n",
    "        #                                        * dumb_log.loc[i, \"Observation\"][-4])})\n",
    "\n",
    "    #dumb_log = pd.concat((dumb_log, pd.DataFrame(real_power_dumb)), axis=1)\n",
    "\n",
    "    mean_per_hid_rl = log_RL.groupby(\"hour_id\").mean()[\"Charging energy\"].reset_index(drop=True)\n",
    "    mean_all_rl = []\n",
    "    for i in range(mean_per_hid_rl.__len__()):\n",
    "        mean_all_rl.append(np.mean(mean_per_hid_rl[i]))\n",
    "\n",
    "    mean_per_hid_dumb = dumb_log.groupby(\"hour_id\").mean()[\"Charging energy\"].reset_index(drop=True)\n",
    "    mean_all_dumb = []\n",
    "    for i in range(mean_per_hid_dumb.__len__()):\n",
    "        mean_all_dumb.append(np.mean(mean_per_hid_dumb[i]))\n",
    "\n",
    "    mean_both = pd.DataFrame()\n",
    "    mean_both[\"RL\"] = np.multiply(mean_all_rl, 4)\n",
    "    mean_both[\"Dumb charging\"] = np.multiply(mean_all_dumb, 4)\n",
    "\n",
    "    mean_both.plot()\n",
    "\n",
    "    plt.xticks([0,8,16,24,32,40,48,56,64,72,80,88]\n",
    "               ,[\"00:00\",\"02:00\",\"04:00\",\"06:00\",\"08:00\",\"10:00\",\"12:00\",\"14:00\",\"16:00\",\"18:00\",\"20:00\",\"22:00\"],\n",
    "               rotation=45)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.2)\n",
    "\n",
    "    plt.ylabel(\"Charging power in kW\")\n",
    "    max = log_RL.loc[0, \"Observation\"][-10]\n",
    "    plt.ylim([-max * 1.2, max * 1.2])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6d4b1-1028-4c76-b63e-fe3e8ffd5bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(total_results)\n",
    "mean_both.plot()\n",
    "\n",
    "plt.xticks([0,8,16,24,32,40,48,56,64,72,80,88]\n",
    "           ,[\"00:00\",\"02:00\",\"04:00\",\"06:00\",\"08:00\",\"10:00\",\"12:00\",\"14:00\",\"16:00\",\"18:00\",\"20:00\",\"22:00\"],\n",
    "           rotation=45)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.2)\n",
    "\n",
    "plt.ylabel(\"Charging power in kW\")\n",
    "max = log_RL.loc[0, \"Observation\"][-10]\n",
    "plt.ylim([-max * 1.2, max * 1.2])\n",
    "#plt.savefig(\"PPO_lmd_arb_single_vast_jul19.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61150f0b-0a14-433b-9e00-81d822868095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "# Create a date range from Jan to Dec\n",
    "# Create a date range from Jan to Dec with a 15-minute resolution\n",
    "date_range = pd.date_range(start=\"2023-01-01\", end=\"2023-12-31\", freq='15min')\n",
    "\n",
    "# Check if the lengths match\n",
    "print(len(date_range) == len(log_RL))  # should print True\n",
    "\n",
    "# Continue with the rest of the code...\n",
    "\n",
    "# Create a figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Rescale the index of the dataframes to match the date range\n",
    "rescaled_log_RL = log_RL.copy()\n",
    "rescaled_log_RL.index = date_range[:len(log_RL)]\n",
    "rescaled_dumb_log = dumb_log.copy()\n",
    "rescaled_dumb_log.index = date_range[:len(dumb_log)]\n",
    "\n",
    "# Plot the data\n",
    "ax.plot(rescaled_dumb_log.index, rescaled_dumb_log['SOH'], label='Dumb', color='red')\n",
    "ax.plot(rescaled_log_RL.index, rescaled_log_RL['SOH'], label='RL', color='blue')\n",
    "\n",
    "\n",
    "# Set the title and labels\n",
    "ax.set_title('State of Health Over Time')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('State of Health')\n",
    "ax.legend()\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels()[0:12])[0:12]\n",
    "ax.set_xticks(ax.get_xticks()[0:12])[0:12]\n",
    "# Show the plot\n",
    "plt.grid(alpha=0.2)\n",
    "plt.savefig(\"PPO_lmd_arb_single_vast_jul19_SOH.pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445033bc-41ed-4c65-a020-f787c76811c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(3,3))\n",
    "\n",
    "# Plot RL data\n",
    "log_RL.loc[log_RL[\"SOC violation\"] > 0, \"SOC violation\"].sort_values(ascending=False).reset_index(drop=True).plot.bar(color=\"blue\", ax=axs)\n",
    "axs.set_title(\"RL-based charging\")\n",
    "axs.set_xticks([0,25,50,75,100])\n",
    "axs.set_ylim([0,0.4])\n",
    "axs.grid(alpha=0.2)\n",
    "axs.set_xlabel(\"Violations\")\n",
    "axs.set_ylabel(\"Missing SOC per violation\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ppo_lmd_arb_soc_vio_vast_jul19.pdf\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c142e-264e-4e71-a976-5d00c5d812a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_RL['Action'] = log_RL['Action'].apply(lambda x: x[0])\n",
    "dumb_log['Action'] = dumb_log['Action'].apply(lambda x: x[0])\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# Plot the distribution of actions for the RL-based strategy on the first subplot\n",
    "axs[0].hist(log_RL['Action'], bins=50, color='blue', edgecolor='black')\n",
    "axs[0].set_title('Distribution of Actions for RL-based Charging')\n",
    "axs[0].set_xlabel('Action')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "# Plot the distribution of actions for the dumb strategy on the second subplot\n",
    "axs[1].hist(dumb_log['Action'], bins=50, color='red', edgecolor='black')\n",
    "axs[1].set_title('Distribution of actions for Dumb Charging')\n",
    "axs[1].set_xlabel('Action')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ppo_lmd_arb_act_dist_vast_jul19.pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a9a43-8d7f-4a42-8680-c20555857b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_RL.to_pickle(\"PPO_final_lmd_arb.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8072888-7f53-4033-9786-335eb553bd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "log_RL = pd.read_pickle(\"./PPO_final_lmd_arb.pickle\")\n",
    "dumb_log = pd.read_pickle(\"./dumb_lmd_arb.pickle\")\n",
    "\n",
    "rl_cashflow = log_RL[\"Cashflow\"].sum()\n",
    "rl_reward = log_RL[\"Reward\"].sum()\n",
    "rl_deg = log_RL[\"Degradation\"].sum()\n",
    "rl_overloading = log_RL[\"Grid overloading\"].sum()\n",
    "rl_soc_violation = log_RL[\"SOC violation\"].sum()\n",
    "rl_n_violations = log_RL[log_RL[\"SOC violation\"] > 0][\"SOC violation\"].size\n",
    "rl_soh = log_RL[\"SOH\"].iloc[-1]\n",
    "\n",
    "dumb_cashflow = dumb_log[\"Cashflow\"].sum()\n",
    "dumb_reward = dumb_log[\"Reward\"].sum()\n",
    "dumb_deg = dumb_log[\"Degradation\"].sum()\n",
    "dumb_overloading = dumb_log[\"Grid overloading\"].sum()\n",
    "dumb_soc_violation = dumb_log[\"SOC violation\"].sum()\n",
    "dumb_n_violations = dumb_log[dumb_log[\"SOC violation\"] > 0][\"SOC violation\"].size\n",
    "dumb_soh = dumb_log[\"SOH\"].iloc[-1]\n",
    "\n",
    "print(f\"RL reward: {rl_reward}\")\n",
    "print(f\"DC reward: {dumb_reward}\")\n",
    "print(f\"RL cashflow: {rl_cashflow}\")\n",
    "print(f\"DC cashflow: {dumb_cashflow}\")\n",
    "\n",
    "total_results = pd.DataFrame()\n",
    "total_results[\"Category\"] = [\"Reward\", \"Cashflow\", \"Average degradation per EV\", \"Overloading\", \"SOC violation\", \"# Violations\", \"SOH\"]\n",
    "\n",
    "total_results[\"RL-based charging\"] = [rl_reward,\n",
    "                                      rl_cashflow,\n",
    "                                      np.round(np.mean(rl_deg), 5),\n",
    "                                      rl_overloading,\n",
    "                                      rl_soc_violation,\n",
    "                                      rl_n_violations,\n",
    "                                      np.round(np.mean(rl_soh), 5)]\n",
    "\n",
    "total_results[\"Dumb charging\"] = [dumb_reward,\n",
    "                                  dumb_cashflow,\n",
    "                                  np.round(np.mean(dumb_deg), 5),\n",
    "                                  dumb_overloading,\n",
    "                                  dumb_soc_violation,\n",
    "                                  dumb_n_violations,\n",
    "                                  np.round(np.mean(dumb_soh), 5)]\n",
    "\n",
    "print(total_results)\n",
    "\n",
    "\n",
    "# real charging power sent\n",
    "real_power_rl = []\n",
    "for i in range(log_RL.__len__()):\n",
    "    log_RL.loc[i, \"hour_id\"] = (log_RL.loc[i, \"Time\"].hour + log_RL.loc[i, \"Time\"].minute / 60)\n",
    "    # real_power_rl.append({\"real_power\": (log_RL.loc[i, \"Action\"]\n",
    "    #                                      * log_RL.loc[i, \"Observation\"][2 * n_evs + 19:2 * n_evs + 19 + n_evs]\n",
    "    #                                      * log_RL.loc[i, \"Observation\"][-4])})\n",
    "\n",
    "#log_RL = pd.concat((log_RL, pd.DataFrame(real_power_rl)), axis=1)\n",
    "\n",
    "real_power_dumb = []\n",
    "for i in range(dumb_log.__len__()):\n",
    "    dumb_log.loc[i, \"hour_id\"] = (dumb_log.loc[i, \"Time\"].hour + dumb_log.loc[i, \"Time\"].minute / 60)\n",
    "    # real_power_dumb.append({\"real_power\": (dumb_log.loc[i, \"Action\"]\n",
    "    #                                        * dumb_log.loc[i, \"Observation\"][2 * n_evs + 19:2 * n_evs + 19 + n_evs]\n",
    "    #                                        * dumb_log.loc[i, \"Observation\"][4 * n_evs + 19:4 * n_evs + 19 + n_evs]\n",
    "    #                                        * dumb_log.loc[i, \"Observation\"][-4])})\n",
    "\n",
    "#dumb_log = pd.concat((dumb_log, pd.DataFrame(real_power_dumb)), axis=1)\n",
    "\n",
    "mean_per_hid_rl = log_RL.groupby(\"hour_id\").mean()[\"Charging energy\"].reset_index(drop=True)\n",
    "mean_all_rl = []\n",
    "for i in range(mean_per_hid_rl.__len__()):\n",
    "    mean_all_rl.append(np.mean(mean_per_hid_rl[i]))\n",
    "\n",
    "mean_per_hid_dumb = dumb_log.groupby(\"hour_id\").mean()[\"Charging energy\"].reset_index(drop=True)\n",
    "mean_all_dumb = []\n",
    "for i in range(mean_per_hid_dumb.__len__()):\n",
    "    mean_all_dumb.append(np.mean(mean_per_hid_dumb[i]))\n",
    "\n",
    "mean_both = pd.DataFrame()\n",
    "mean_both[\"RL\"] = np.multiply(mean_all_rl, 4)\n",
    "mean_both[\"Dumb charging\"] = np.multiply(mean_all_dumb, 4)\n",
    "\n",
    "mean_both.plot()\n",
    "\n",
    "plt.xticks([0,8,16,24,32,40,48,56,64,72,80,88]\n",
    "           ,[\"00:00\",\"02:00\",\"04:00\",\"06:00\",\"08:00\",\"10:00\",\"12:00\",\"14:00\",\"16:00\",\"18:00\",\"20:00\",\"22:00\"],\n",
    "           rotation=45)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.2)\n",
    "\n",
    "plt.ylabel(\"Charging power in kW\")\n",
    "max = log_RL.loc[0, \"Observation\"][-10]\n",
    "plt.ylim([-max * 1.2, max * 1.2])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
