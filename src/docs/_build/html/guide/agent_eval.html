<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Agent Evaluation &mdash; FleetRL 1.0.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=8d563738"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Benchmarking" href="benchmarking.html" />
    <link rel="prev" title="Agent Training" href="agent_training.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            FleetRL
          </a>
              <div class="version">
                master (1.0.0 )
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_env.html">Creating a custom environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="agent_training.html">Agent Training</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Agent Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../FleetRL.fleet_env.html">Fleet Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FleetRL.utils.data_logger.html">Data logger</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FleetRL.utils.load_calculation.html">Load calculation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FleetRL.utils.normalization.html">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FleetRL.utils.observation.html">Observation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FleetRL.utils.schedule.html">Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FleetRL.utils.time_picker.html">Time picker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FleetRL.utils.data_processing.html">Data processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FleetRL.utils.ev_charging.html">EV charging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FleetRL.utils.battery_degradation.html">Battery degradation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">FleetRL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Agent Evaluation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/guide/agent_eval.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="agent-evaluation">
<span id="agent-eval"></span><h1>Agent Evaluation<a class="headerlink" href="#agent-evaluation" title="Link to this heading">ÔÉÅ</a></h1>
<p>Agent evaluation requires a trained RL agent, in form of a .zip artifact generated from SB3.
The evaluation features a comparison with uncontrolled charging to allow for a first basic
comparison. It is optional and can be toggled off to save compute time.</p>
<p><strong>Import requirements</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">datetime</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.evaluation</span> <span class="kn">import</span> <span class="n">evaluate_policy</span>
<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">TD3</span><span class="p">,</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.vec_env</span> <span class="kn">import</span> <span class="n">VecNormalize</span><span class="p">,</span> <span class="n">SubprocVecEnv</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>
<span class="kn">from</span> <span class="nn">FleetRL.fleet_env.fleet_environment</span> <span class="kn">import</span> <span class="n">FleetEnv</span>
</pre></div>
</div>
<p><strong>Multi-processing wrapper</strong></p>
<p>The evaluation uses vectorized environments that allow for parallelization. If this script is
run in a Jupyter notebook, no changes need to be made. If, however, the script is run as a .py
file, it needs to be wrapped as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># code here</span>
</pre></div>
</div>
<p><strong>Defining fundamental parameters</strong></p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">n_steps</span></code> is set to 8600. This means that the evaluation episode is set to 8600
hours. The trained agent is therefore tested on one year of unseen schedule data. A separately
generated schedule is used that the agent did not see during training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define parameters here for easier change</span>
<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">8600</span>
<span class="n">n_episodes</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_evs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_envs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">file_name_comment</span> <span class="o">=</span> <span class="s2">&quot;comment&quot;</span>  <span class="c1"># added to log pickle file names</span>
</pre></div>
</div>
<p><strong>Environment creation</strong></p>
<p>The testing environment is created. The parameters are the same as for training - only
the schedule differs: <code class="docutils literal notranslate"><span class="pre">lmd_sched_single_eval.csv</span></code>. The same normalization and vectorization is performed.
Generally, agents are cross-compatible with environments of same dimension and boundaries. A 1-car agent
trained on the environment for caretakers can thus be used on the last-mile delivery environment, if
the <code class="docutils literal notranslate"><span class="pre">gym.Spaces</span></code> bounds are the same. If normalization is conducted in FleetRL, the bounds are [0,1]. If
no normalization is conducted, the bounds are [-inf, inf]. This ensures maximum cross-compatibility.
Similarly, the environment for the uncontrolled charging agent is created (<code class="docutils literal notranslate"><span class="pre">dumb_vec_env,</span> <span class="pre">dumb_norm_vec_env</span></code>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># make env for the agent</span>
<span class="n">eval_vec_env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="n">FleetEnv</span><span class="p">,</span>
                            <span class="n">n_envs</span><span class="o">=</span><span class="n">n_envs</span><span class="p">,</span>
                            <span class="n">vec_env_cls</span><span class="o">=</span><span class="n">SubprocVecEnv</span><span class="p">,</span>
                            <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="n">env_kwargs</span><span class="o">=</span><span class="p">{</span>
                                <span class="s2">&quot;schedule_name&quot;</span><span class="p">:</span> <span class="s2">&quot;lmd_sched_single_eval.csv&quot;</span><span class="p">,</span>  <span class="c1"># separate testing schedule</span>
                                <span class="s2">&quot;building_name&quot;</span><span class="p">:</span> <span class="s2">&quot;load_lmd.csv&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;price_name&quot;</span><span class="p">:</span> <span class="s2">&quot;spot_2021_new.csv&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;tariff_name&quot;</span><span class="p">:</span> <span class="s2">&quot;spot_2021_new_tariff.csv&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;use_case&quot;</span><span class="p">:</span> <span class="s2">&quot;lmd&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;include_building&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;include_pv&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;time_picker&quot;</span><span class="p">:</span> <span class="s2">&quot;static&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;deg_emp&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;include_price&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;ignore_price_reward&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;ignore_invalid_penalty&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;ignore_overcharging_penalty&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;ignore_overloading_penalty&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;episode_length&quot;</span><span class="p">:</span> <span class="n">n_steps</span><span class="p">,</span>
                                <span class="s2">&quot;normalize_in_env&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                                <span class="s2">&quot;aux&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;log_data&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;calculate_degradation&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;spot_markup&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                                <span class="s2">&quot;spot_mul&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                                <span class="s2">&quot;feed_in_ded&quot;</span><span class="p">:</span> <span class="mi">0</span>
                            <span class="p">})</span>

<span class="n">eval_norm_vec_env</span> <span class="o">=</span> <span class="n">VecNormalize</span><span class="p">(</span><span class="n">venv</span><span class="o">=</span><span class="n">eval_vec_env</span><span class="p">,</span>
                                 <span class="n">norm_obs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">norm_reward</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">clip_reward</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>

<span class="n">dumb_vec_env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="n">FleetEnv</span><span class="p">,</span>
                            <span class="n">n_envs</span><span class="o">=</span><span class="n">n_envs</span><span class="p">,</span>
                            <span class="n">vec_env_cls</span><span class="o">=</span><span class="n">SubprocVecEnv</span><span class="p">,</span>
                            <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="n">env_kwargs</span><span class="o">=</span><span class="p">{</span>
                                <span class="s2">&quot;schedule_name&quot;</span><span class="p">:</span> <span class="s2">&quot;lmd_sched_single_eval.csv&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;building_name&quot;</span><span class="p">:</span> <span class="s2">&quot;load_lmd.csv&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;price_name&quot;</span><span class="p">:</span> <span class="s2">&quot;spot_2021_new.csv&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;tariff_name&quot;</span><span class="p">:</span> <span class="s2">&quot;spot_2021_new_tariff.csv&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;use_case&quot;</span><span class="p">:</span> <span class="s2">&quot;lmd&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;include_building&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;include_pv&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;time_picker&quot;</span><span class="p">:</span> <span class="s2">&quot;static&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;deg_emp&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;include_price&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;ignore_price_reward&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;ignore_invalid_penalty&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;ignore_overcharging_penalty&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;ignore_overloading_penalty&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;episode_length&quot;</span><span class="p">:</span> <span class="n">n_steps</span><span class="p">,</span>
                                <span class="s2">&quot;normalize_in_env&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                                <span class="s2">&quot;aux&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;log_data&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;calculate_degradation&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                <span class="s2">&quot;spot_markup&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                                <span class="s2">&quot;spot_mul&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                                <span class="s2">&quot;feed_in_ded&quot;</span><span class="p">:</span> <span class="mi">0</span>
                            <span class="p">})</span>

<span class="n">dumb_norm_vec_env</span> <span class="o">=</span> <span class="n">VecNormalize</span><span class="p">(</span><span class="n">venv</span><span class="o">=</span><span class="n">dumb_vec_env</span><span class="p">,</span>
                                 <span class="n">norm_obs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">norm_reward</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">clip_reward</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Loading models</strong></p>
<p>The normalization metrics can be loaded via <code class="docutils literal notranslate"><span class="pre">VecEnv.load(load_path,</span> <span class="pre">venv)</span></code>. This is optional.
The RL agent is loaded. The path to the .zip artifact and the environment must be specified.
Optionally, a custom_objects parameter can be parsed to make sure that observation and action space
are correctly configured.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">eval_norm_vec_env</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">load_path</span><span class="o">=</span><span class="s2">&quot;./tmp/vec_PPO/vec_normalize-LMD_2021_arbitrage_PPO_mul3.pkl&quot;</span><span class="p">,</span> <span class="n">venv</span><span class="o">=</span><span class="n">eval_norm_vec_env</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;./tmp/vec_PPO/PPO-fleet_LMD_2021_arbitrage_PPO_mul3.zip&quot;</span><span class="p">,</span> <span class="n">env</span> <span class="o">=</span> <span class="n">eval_norm_vec_env</span><span class="p">,</span>
                <span class="n">custom_objects</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;observation_space&quot;</span><span class="p">:</span> <span class="n">eval_norm_vec_env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span>
                               <span class="s2">&quot;action_space&quot;</span><span class="p">:</span> <span class="n">eval_norm_vec_env</span><span class="o">.</span><span class="n">action_space</span><span class="p">})</span>
</pre></div>
</div>
<p><strong>RL agent evaluation</strong></p>
<p>Agents are evaluated via <code class="docutils literal notranslate"><span class="pre">evaluate_policy</span></code>. The model, the environment, the number of episodes and the
deterministic flag are parsed. <code class="docutils literal notranslate"><span class="pre">deterministic=True</span></code> ensures that several evaluations of the same
agents yield the same results - ensuring reproducibility. Random fluctuations due to random number generators
or statistical distributions are eliminated.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mean_reward</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate_policy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">eval_norm_vec_env</span><span class="p">,</span> <span class="n">n_eval_episodes</span><span class="o">=</span><span class="n">n_episodes</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_reward</span><span class="p">)</span>
</pre></div>
</div>
<p>Once <code class="docutils literal notranslate"><span class="pre">evaluate_policy</span></code> concluded, the environment stepped through 8600 hours. Meanwhile,
FleetRL logged every important metric, allowing for post-processing and thorough analyses.
These can be accessed via <code class="docutils literal notranslate"><span class="pre">env_method(&quot;get_log&quot;)[0]</span></code>, as shown below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">log_RL</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">env_method</span><span class="p">(</span><span class="s2">&quot;get_log&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p><strong>Uncontrolled charging agent</strong></p>
<p>The start time of the evaluation environment is extracted and set as start time for the
uncontrolled charging environment. The environment is then stepped through for the same amount
of time steps and the log is extracted.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># start date extraction and setting the same date to the uncontrolled charging env</span>
<span class="n">rl_start_time</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">env_method</span><span class="p">(</span><span class="s2">&quot;get_start_time&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">dumb_norm_vec_env</span><span class="o">.</span><span class="n">env_method</span><span class="p">(</span><span class="s2">&quot;set_start_time&quot;</span><span class="p">,</span> <span class="n">rl_start_time</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;################################################################&quot;</span><span class="p">)</span>

<span class="n">episode_length</span> <span class="o">=</span> <span class="n">n_steps</span>
<span class="n">timesteps_per_hour</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_episodes</span> <span class="o">=</span> <span class="n">n_episodes</span>
<span class="n">dumb_norm_vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="c1"># uncontrolled charging agent: action of &quot;1&quot; is sent for each time step -&gt; charging immediately upon arrival</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">episode_length</span> <span class="o">*</span> <span class="n">timesteps_per_hour</span> <span class="o">*</span> <span class="n">n_episodes</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">dumb_norm_vec_env</span><span class="o">.</span><span class="n">env_method</span><span class="p">(</span><span class="s2">&quot;is_done&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">dumb_norm_vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">dumb_norm_vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_evs</span><span class="p">)])</span>

<span class="c1"># log extraction from the vec_env</span>
<span class="n">dumb_log</span> <span class="o">=</span> <span class="n">dumb_norm_vec_env</span><span class="o">.</span><span class="n">env_method</span><span class="p">(</span><span class="s2">&quot;get_log&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p><strong>Post-processing</strong></p>
<p>Once both agents ran in the environments and the logs have been extracted, they can be used to
extract useful information on charging expenses, state of health, violations, rewards, etc.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># index reset and the last row of the dataframe is removed</span>
<span class="n">log_RL</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">log_RL</span> <span class="o">=</span> <span class="n">log_RL</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="n">dumb_log</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dumb_log</span> <span class="o">=</span> <span class="n">dumb_log</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>

<span class="c1"># computing key performance metrics</span>
<span class="n">rl_cashflow</span> <span class="o">=</span> <span class="n">log_RL</span><span class="p">[</span><span class="s2">&quot;Cashflow&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">rl_reward</span> <span class="o">=</span> <span class="n">log_RL</span><span class="p">[</span><span class="s2">&quot;Reward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">rl_deg</span> <span class="o">=</span> <span class="n">log_RL</span><span class="p">[</span><span class="s2">&quot;Degradation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">rl_overloading</span> <span class="o">=</span> <span class="n">log_RL</span><span class="p">[</span><span class="s2">&quot;Grid overloading&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">rl_soc_violation</span> <span class="o">=</span> <span class="n">log_RL</span><span class="p">[</span><span class="s2">&quot;SOC violation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">rl_n_violations</span> <span class="o">=</span> <span class="n">log_RL</span><span class="p">[</span><span class="n">log_RL</span><span class="p">[</span><span class="s2">&quot;SOC violation&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">][</span><span class="s2">&quot;SOC violation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span>
<span class="n">rl_soh</span> <span class="o">=</span> <span class="n">log_RL</span><span class="p">[</span><span class="s2">&quot;SOH&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">dumb_cashflow</span> <span class="o">=</span> <span class="n">dumb_log</span><span class="p">[</span><span class="s2">&quot;Cashflow&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">dumb_reward</span> <span class="o">=</span> <span class="n">dumb_log</span><span class="p">[</span><span class="s2">&quot;Reward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">dumb_deg</span> <span class="o">=</span> <span class="n">dumb_log</span><span class="p">[</span><span class="s2">&quot;Degradation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">dumb_overloading</span> <span class="o">=</span> <span class="n">dumb_log</span><span class="p">[</span><span class="s2">&quot;Grid overloading&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">dumb_soc_violation</span> <span class="o">=</span> <span class="n">dumb_log</span><span class="p">[</span><span class="s2">&quot;SOC violation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">dumb_n_violations</span> <span class="o">=</span> <span class="n">dumb_log</span><span class="p">[</span><span class="n">dumb_log</span><span class="p">[</span><span class="s2">&quot;SOC violation&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">][</span><span class="s2">&quot;SOC violation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span>
<span class="n">dumb_soh</span> <span class="o">=</span> <span class="n">dumb_log</span><span class="p">[</span><span class="s2">&quot;SOH&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;RL reward: </span><span class="si">{</span><span class="n">rl_reward</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DC reward: </span><span class="si">{</span><span class="n">dumb_reward</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;RL cashflow: </span><span class="si">{</span><span class="n">rl_cashflow</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DC cashflow: </span><span class="si">{</span><span class="n">dumb_cashflow</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">total_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">total_results</span><span class="p">[</span><span class="s2">&quot;Category&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Reward&quot;</span><span class="p">,</span> <span class="s2">&quot;Cashflow&quot;</span><span class="p">,</span> <span class="s2">&quot;Average degradation per EV&quot;</span><span class="p">,</span> <span class="s2">&quot;Overloading&quot;</span><span class="p">,</span> <span class="s2">&quot;SOC violation&quot;</span><span class="p">,</span> <span class="s2">&quot;# Violations&quot;</span><span class="p">,</span> <span class="s2">&quot;SOH&quot;</span><span class="p">]</span>

<span class="n">total_results</span><span class="p">[</span><span class="s2">&quot;RL-based charging&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">rl_reward</span><span class="p">,</span>
                                      <span class="n">rl_cashflow</span><span class="p">,</span>
                                      <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rl_deg</span><span class="p">),</span> <span class="mi">5</span><span class="p">),</span>
                                      <span class="n">rl_overloading</span><span class="p">,</span>
                                      <span class="n">rl_soc_violation</span><span class="p">,</span>
                                      <span class="n">rl_n_violations</span><span class="p">,</span>
                                      <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rl_soh</span><span class="p">),</span> <span class="mi">5</span><span class="p">)]</span>

<span class="n">total_results</span><span class="p">[</span><span class="s2">&quot;Dumb charging&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">dumb_reward</span><span class="p">,</span>
                                  <span class="n">dumb_cashflow</span><span class="p">,</span>
                                  <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dumb_deg</span><span class="p">),</span> <span class="mi">5</span><span class="p">),</span>
                                  <span class="n">dumb_overloading</span><span class="p">,</span>
                                  <span class="n">dumb_soc_violation</span><span class="p">,</span>
                                  <span class="n">dumb_n_violations</span><span class="p">,</span>
                                  <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dumb_soh</span><span class="p">),</span> <span class="mi">5</span><span class="p">)]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">total_results</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Plotting</strong></p>
<p>As an example, the charging strategies of the RL agent and the uncontrolled charging strategy are plotted - the mean
of each quarter hour is plotted, indicating when charging signals are sent to the battery.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># real charging power sent to the battery</span>
<span class="n">real_power_rl</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">log_RL</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()):</span>
    <span class="n">log_RL</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;hour_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">log_RL</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hour</span> <span class="o">+</span> <span class="n">log_RL</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minute</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>

<span class="n">real_power_dumb</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dumb_log</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()):</span>
    <span class="n">dumb_log</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;hour_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">dumb_log</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hour</span> <span class="o">+</span> <span class="n">dumb_log</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minute</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>

<span class="c1"># computing the average for each quarter hour over the entire year</span>
<span class="n">mean_per_hid_rl</span> <span class="o">=</span> <span class="n">log_RL</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;hour_id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()[</span><span class="s2">&quot;Charging energy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mean_all_rl</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mean_per_hid_rl</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()):</span>
    <span class="n">mean_all_rl</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_per_hid_rl</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="n">mean_per_hid_dumb</span> <span class="o">=</span> <span class="n">dumb_log</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;hour_id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()[</span><span class="s2">&quot;Charging energy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mean_all_dumb</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mean_per_hid_dumb</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()):</span>
    <span class="n">mean_all_dumb</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_per_hid_dumb</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="c1"># multiplied by the factor of 4 to go from kWh to kW (15 min time resolution)</span>
<span class="n">mean_both</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">mean_both</span><span class="p">[</span><span class="s2">&quot;RL&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">mean_all_rl</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">mean_both</span><span class="p">[</span><span class="s2">&quot;Dumb charging&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">mean_all_dumb</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># plotting</span>
<span class="n">mean_both</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">48</span><span class="p">,</span><span class="mi">56</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">72</span><span class="p">,</span><span class="mi">80</span><span class="p">,</span><span class="mi">88</span><span class="p">],</span>
           <span class="p">[</span><span class="s2">&quot;00:00&quot;</span><span class="p">,</span><span class="s2">&quot;02:00&quot;</span><span class="p">,</span><span class="s2">&quot;04:00&quot;</span><span class="p">,</span><span class="s2">&quot;06:00&quot;</span><span class="p">,</span><span class="s2">&quot;08:00&quot;</span><span class="p">,</span><span class="s2">&quot;10:00&quot;</span><span class="p">,</span><span class="s2">&quot;12:00&quot;</span><span class="p">,</span><span class="s2">&quot;14:00&quot;</span><span class="p">,</span><span class="s2">&quot;16:00&quot;</span><span class="p">,</span><span class="s2">&quot;18:00&quot;</span><span class="p">,</span><span class="s2">&quot;20:00&quot;</span><span class="p">,</span><span class="s2">&quot;22:00&quot;</span><span class="p">],</span>
           <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Charging power in kW&quot;</span><span class="p">)</span>
<span class="nb">max</span> <span class="o">=</span> <span class="n">log_RL</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Observation&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">10</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="nb">max</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">,</span> <span class="nb">max</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/single_lmd_1year_mul3_real.png"><img alt="Exemplary charging curve for last-mile delivery" src="../_images/single_lmd_1year_mul3_real.png" style="width: 300px;" /></a>
<p><strong>Saving the logs for future use</strong></p>
<p>The logs can be saved as pickle files, so the same analytics and other visualizations can be performed
on another machine, or at a later point in time.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dumb_log</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dumb_log_</span><span class="si">{</span><span class="n">file_name_comment</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">log_rl</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rl_log_</span><span class="si">{</span><span class="n">file_name_comment</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Example of what can be done in post-processing</p>
<a class="reference internal image-reference" href="../_images/showcase_5_ct_v3.pdf"><img alt="Exemplary charging curve for last-mile delivery" src="../_images/showcase_5_ct_v3.pdf" style="width: 300px;" /></a>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="agent_training.html" class="btn btn-neutral float-left" title="Agent Training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="benchmarking.html" class="btn btn-neutral float-right" title="Benchmarking" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Enzo Alexander Cording.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>